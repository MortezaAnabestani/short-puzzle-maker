import React, { useState, useCallback, useEffect, useRef } from "react";
import {
  ArtStyle,
  PieceShape,
  PieceMaterial,
  MovementType,
  PuzzleState,
  UserPreferences,
  TopicType,
  StoryArc,
} from "../types";
import {
  generateArtImage,
  YouTubeMetadata,
  getTrendingTopics,
  fetchFactNarrative,
  generateCoherentContentPackage,
  findSmartMusicByMood,
  extractCoreSubject,
} from "../services/geminiService";
import { getJalaliDate } from "../utils/dateUtils";
import { MusicTrack } from "../components/sidebar/MusicUploader";
import { VIRAL_CATEGORIES } from "../components/sidebar/VisionInput";
import { selectFreshCategory, addTopicVariation } from "../utils/contentVariety";
import { contentApi, ContentPayload } from "../services/api/contentApi";
import { sonicEngine } from "../services/proceduralAudio";

export type PipelineStep =
  | "IDLE"
  | "SCAN"
  | "MUSIC"
  | "SYNTH"
  | "METADATA"
  | "THUMBNAIL"
  | "ANIMATE"
  | "RECORDING"
  | "PACKAGING";

export interface ProductionStep {
  id: string;
  label: string;
  status: "pending" | "in_progress" | "completed" | "error";
  details?: string;
}

const CLOUDFLARE_WORKER_URL = "https://plain-tooth-75c3.jujube-bros.workers.dev/";

interface QueueItem {
  duration: number;
  source: "BREAKING" | "VIRAL" | "NARRATIVE";
  pieceCount: number;
}

/**
 * ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ù…Ø·Ø§Ø¨Ù‚ AUTO_PILOT_STRATEGY.md
 */
const randomizeVisualParameters = () => {
  const artStyles = Object.values(ArtStyle);
  const movements = Object.values(MovementType);
  const materials = Object.values(PieceMaterial);
  const shapes = Object.values(PieceShape);

  const randomStyle = artStyles[Math.floor(Math.random() * artStyles.length)];
  const randomMovement = movements[Math.floor(Math.random() * movements.length)];
  const randomMaterial = materials[Math.floor(Math.random() * materials.length)];
  const randomShape = shapes[Math.floor(Math.random() * shapes.length)];

  console.log(
    `ğŸ­ [VARIETY] Style: ${randomStyle}, Movement: ${randomMovement}, Material: ${randomMaterial}, Shape: ${randomShape}`
  );

  return { randomStyle, randomMovement, randomMaterial, randomShape };
};

/**
 * Ø§Ù†ØªØ®Ø§Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ: Manual â†’ Backend â†’ AI
 */
interface SmartMusicSelectionParams {
  musicTracks: MusicTrack[];
  queueIndex: number;
  musicMood: any;
  topic: string;
  fetchAudioBlob: (url: string) => Promise<string | null>;
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void;
  setActiveTrackName: (name: string | null) => void;
  audioRef: React.RefObject<HTMLAudioElement | null>;
}

/**
 * Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø±Ø§ Ø¯ÛŒÚ©Ø¯ Ú©Ø±Ø¯Ù‡ Ø¯Ø± musicBufferRef Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
 * Ø§Ú¯Ø± blob Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ Ù‡Ù…Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¨Ø¯ÙˆÙ† fetch Ù…Ø¬Ø¯Ø¯) ØªØ§ Ø¯Ø± Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ AI Studio Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ©Ø¯ Ù†Ø¯Ù‡Ø¯.
 */
const decodeAndStoreMusicBuffer = async (
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>,
  blobOrNull?: Blob | null
): Promise<void> => {
  const ctx = sonicEngine.getContext();
  if (!ctx) {
    console.warn(`âš ï¸ [MUSIC] No AudioContext for decode`);
    return;
  }
  // Ø¨Ø§ÙØ± Ù‚Ø¨Ù„ÛŒ Ø±Ø§ ØªØ§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯ÛŒÚ©Ø¯ Ø¬Ø¯ÛŒØ¯ Ù¾Ø§Ú© Ù†Ú©Ù† ØªØ§ Ø§Ø² ÙˆÛŒØ¯Ø¦ÙˆÛŒ Ø¯ÙˆÙ… Ø¨Ù‡ Ø¨Ø¹Ø¯ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø­ÙØ¸ Ø¨Ù…Ø§Ù†Ø¯

  let arrayBuffer: ArrayBuffer;
  if (blobOrNull && blobOrNull.size > 0 && !blobOrNull.type.startsWith("text/")) {
    try {
      arrayBuffer = await blobOrNull.arrayBuffer();
    } catch (e) {
      console.warn(`âš ï¸ [MUSIC] Blob.arrayBuffer() failed:`, e);
      return;
    }
  } else {
    const el = audioRef.current;
    const url = el?.src || el?.currentSrc;
    if (!url || url === "" || url === "about:blank") return;
    try {
      const res = await fetch(url);
      if (!res.ok) throw new Error(`Fetch ${res.status}`);
      const blob = await res.blob();
      if (blob.size === 0 || blob.type.startsWith("text/")) {
        console.warn(`âš ï¸ [MUSIC] Fetched response is not audio (size=${blob.size}, type=${blob.type})`);
        return;
      }
      arrayBuffer = await blob.arrayBuffer();
    } catch (e) {
      console.warn(`âš ï¸ [MUSIC] Fetch for decode failed:`, e);
      return;
    }
  }

  try {
    const decoded = await ctx.decodeAudioData(arrayBuffer.slice(0));
    musicBufferRef.current = decoded;
    console.log(
      `ğŸµ [MUSIC] Decoded to AudioBuffer (${(decoded.length / decoded.sampleRate).toFixed(
        1
      )}s) â€” Web Audio API`
    );
  } catch (e) {
    console.warn(`âš ï¸ [MUSIC] Decode failed (keeping previous buffer if any):`, e);
    // Ø¨Ø§ÙØ± Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ… ØªØ§ Ø¶Ø¨Ø· Ø¨Ø¹Ø¯ÛŒ Ø­Ø¯Ø§Ù‚Ù„ Ù‡Ù…Ø§Ù† Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
  }
};

const selectSmartMusic = async (
  params: SmartMusicSelectionParams
): Promise<{ source: string; title: string; blob?: Blob } | null> => {
  const {
    musicTracks,
    queueIndex,
    musicMood,
    topic,
    fetchAudioBlob,
    onAddCloudTrack,
    setActiveTrackName,
    audioRef,
  } = params;

  // Priority 1: Manual tracks only (filter out backend/ai tracks)
  const manualTracks = musicTracks.filter((track) => track.source === "manual");
  if (manualTracks.length > 0) {
    const selectedTrack = manualTracks[queueIndex % manualTracks.length];
    console.log(
      `ğŸµ [MUSIC] Source: Manual (${(queueIndex % manualTracks.length) + 1}/${manualTracks.length}), Track: ${
        selectedTrack.name
      }`
    );

    // Load music to audioRef
    if (audioRef.current) {
      console.log(`   ğŸ”Š Loading manual track to audio player...`);
      console.log(`      Track URL: ${selectedTrack.url.substring(0, 80)}...`);
      audioRef.current.src = selectedTrack.url;
      audioRef.current.load();
      console.log(`      Audio element readyState: ${audioRef.current.readyState}`);
      console.log(`   âœ… Music loaded to audio player`);
    } else {
      console.error(`   âŒ audioRef.current is null!`);
    }

    setActiveTrackName(selectedTrack.name);
    return { source: "Manual Upload", title: selectedTrack.name };
  }

  // Priority 2 & 3: Backend (Ø¯Ø± smartFetcher Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯) ÛŒØ§ AI
  console.log(`ğŸµ [MUSIC] No manual tracks, using smartFetcher...`);
  const { smartFetcher } = await import("../services/smartFetcher");
  const trackData = await smartFetcher.fetchMusic(musicMood, topic);

  if (trackData && trackData.url) {
    const result = await fetchAudioBlob(trackData.url);
    if (result) {
      const { url: blobUrl, blob } = result;
      const sourceType = trackData.source === "Backend Database" ? "backend" : "ai";
      onAddCloudTrack(blobUrl, trackData.title, sourceType);
      setActiveTrackName(trackData.title);

      if (audioRef.current) {
        console.log(`   ğŸ”Š Loading cloud track to audio player...`);
        console.log(`      Track source: ${trackData.source}, blob size: ${(blob.size / 1024).toFixed(1)}KB`);
        audioRef.current.src = blobUrl;
        audioRef.current.load();
        console.log(`   âœ… Music loaded to audio player`);
      } else {
        console.error(`   âŒ audioRef.current is null!`);
      }

      console.log(`ğŸµ [MUSIC] Source: ${trackData.source}, Track: ${trackData.title}`);
      return { source: trackData.source, title: trackData.title, blob };
    }
  }

  console.warn(`âš ï¸ [MUSIC] No music found`);
  return null;
};

export const useProductionPipeline = (
  preferences: UserPreferences,
  setPreferences: React.Dispatch<React.SetStateAction<UserPreferences>>,
  musicTracks: MusicTrack[],
  selectedTrackId: string | null,
  setActiveTrackName: (name: string | null) => void,
  onAddCloudTrack: (url: string, title: string, source?: "backend" | "ai") => void,
  audioRef: React.RefObject<HTMLAudioElement | null>,
  musicBufferRef: React.MutableRefObject<AudioBuffer | null>
) => {
  const [state, setState] = useState<
    PuzzleState & {
      audioError: boolean;
      isAutoMode: boolean;
      pipelineStep: PipelineStep;
      isFullPackage: boolean;
      queue: QueueItem[];
      currentQueueIdx: number;
      docSnippets: string[];
      storyArc: StoryArc | null;
      productionSteps: ProductionStep[];
    }
  >({
    isGenerating: false,
    isSolving: false,
    isRecording: false,
    progress: 0,
    imageUrl: null,
    error: null,
    audioError: false,
    isAutoMode: false,
    pipelineStep: "IDLE",
    isFullPackage: false,
    queue: [],
    currentQueueIdx: -1,
    docSnippets: [],
    storyArc: null,
    productionSteps: [],
  });

  const [metadata, setMetadata] = useState<YouTubeMetadata | null>(null);
  const [isMetadataLoading, setIsMetadataLoading] = useState(false);
  const [thumbnailDataUrl, setThumbnailDataUrl] = useState<string | null>(null);
  const [lastVideoBlob, setLastVideoBlob] = useState<Blob | null>(null);
  const [currentCoreSubject, setCurrentCoreSubject] = useState<string | null>(null);
  const [currentVisualPrompt, setCurrentVisualPrompt] = useState<string | null>(null);
  const [currentMusicInfo, setCurrentMusicInfo] = useState<{ source: string; title: string } | null>(null);
  const [currentSource, setCurrentSource] = useState<"VIRAL" | "BREAKING" | "NARRATIVE" | "MANUAL">("MANUAL");
  const [currentSimilarityScore, setCurrentSimilarityScore] = useState<number | undefined>(undefined);
  const isExportingRef = useRef(false);

  // Helper function to update production steps
  const updateProductionStep = useCallback(
    (stepId: string, status: ProductionStep["status"], details?: string) => {
      setState((prev) => {
        const existingStepIndex = prev.productionSteps.findIndex((s) => s.id === stepId);

        if (existingStepIndex >= 0) {
          // Update existing step
          const updatedSteps = [...prev.productionSteps];
          updatedSteps[existingStepIndex] = {
            ...updatedSteps[existingStepIndex],
            status,
            details: details || updatedSteps[existingStepIndex].details,
          };
          return { ...prev, productionSteps: updatedSteps };
        } else {
          // Add new step
          return {
            ...prev,
            productionSteps: [...prev.productionSteps, { id: stepId, label: stepId, status, details }],
          };
        }
      });
    },
    []
  );

  // Initialize production steps
  const initializeProductionSteps = useCallback(() => {
    const steps: ProductionStep[] = [
      { id: "ğŸ“Š SCAN", label: "Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§", status: "pending" },
      { id: "ğŸ”Š SOUND FX", label: "ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø§ÙÚ©Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ", status: "pending" },
      { id: "ğŸ­ VARIETY", label: "ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ", status: "pending" },
      { id: "ğŸ” VALIDATION", label: "Ø¨Ø±Ø±Ø³ÛŒ ØªØ´Ø§Ø¨Ù‡ Ù…Ø­ØªÙˆØ§", status: "pending" },
      { id: "ğŸµ MUSIC", label: "Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ³ÛŒÙ‚ÛŒ", status: "pending" },
      { id: "ğŸ¨ GENERATE", label: "ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ùˆ Ø¯Ø§Ø³ØªØ§Ù†", status: "pending" },
      { id: "ğŸ“ METADATA", label: "ØªÙˆÙ„ÛŒØ¯ Ù…ØªØ§Ø¯ÛŒØªØ§", status: "pending" },
      { id: "ğŸ–¼ï¸ THUMBNAIL", label: "Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ§Ù…Ø¨Ù†ÛŒÙ„", status: "pending" },
      { id: "ğŸ¬ ANIMATE", label: "Ø´Ø±ÙˆØ¹ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ù¾Ø§Ø²Ù„", status: "pending" },
      { id: "ğŸ¥ RECORD", label: "Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ", status: "pending" },
      { id: "ğŸ“¦ PACKAGE", label: "Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯", status: "pending" },
    ];
    setState((prev) => ({ ...prev, productionSteps: steps }));
  }, []);

  const downloadFile = (name: string, blob: Blob) => {
    const url = URL.createObjectURL(blob);
    const link = document.createElement("a");
    link.href = url;
    link.download = name;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    setTimeout(() => URL.revokeObjectURL(url), 3000);
  };

  const fetchAudioBlob = async (url: string): Promise<{ url: string; blob: Blob } | null> => {
    const proxies = [
      { url: `${CLOUDFLARE_WORKER_URL}?url=${encodeURIComponent(url)}` },
      { url: `https://api.allorigins.win/raw?url=${encodeURIComponent(url)}` },
    ];
    for (const p of proxies) {
      try {
        const res = await fetch(p.url);
        if (res.ok) {
          let blob = await res.blob();
          if (!blob.type || blob.type === "application/octet-stream") {
            blob = new Blob([blob], { type: "audio/mpeg" });
            console.log(`ğŸµ [fetchAudioBlob] Fixed blob MIME type to audio/mpeg`);
          }
          const blobUrl = URL.createObjectURL(blob);
          console.log(`âœ… [fetchAudioBlob] Created blob URL, size=${(blob.size / 1024).toFixed(1)}KB`);
          return { url: blobUrl, blob };
        }
      } catch (e) {
        console.warn("Proxy fail:", p.url);
      }
    }
    console.error(`âŒ [fetchAudioBlob] All proxies failed for: ${url}`);
    return null;
  };

  const executePackaging = useCallback(
    async (videoBlob: Blob) => {
      console.log(`ğŸ“¦ [Packaging] executePackaging called`);
      console.log(`   isExportingRef: ${isExportingRef.current}`);
      console.log(`   videoBlob size: ${(videoBlob.size / 1024 / 1024).toFixed(2)}MB`);

      if (isExportingRef.current) {
        console.log(`â¸ï¸ [Packaging] Already exporting, skipping...`);
        return;
      }
      isExportingRef.current = true;

      const jalali = getJalaliDate();
      const cleanTitle = (metadata?.title || "Studio_Project").replace(/[\\/:*?"<>|]/g, "").slice(0, 50);
      const baseFileName = `${jalali}_${cleanTitle}`;

      // Step 9: PACKAGE - Export and save
      updateProductionStep("ğŸ“¦ PACKAGE", "in_progress", "Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ...");
      console.log(`ğŸ“¥ [Packaging] Starting downloads with base filename: ${baseFileName}`);

      try {
        console.log(`   1ï¸âƒ£ Downloading video...`);
        downloadFile(`${baseFileName}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`, videoBlob);

        if (metadata) {
          console.log(`   2ï¸âƒ£ Downloading metadata...`);
          await new Promise((r) => setTimeout(r, 1500));
          downloadFile(
            `${baseFileName}_Metadata.txt`,
            new Blob([`TITLE: ${metadata.title}\n\nDESC: ${metadata.description}`], { type: "text/plain" })
          );
        }

        if (thumbnailDataUrl) {
          console.log(`   3ï¸âƒ£ Downloading thumbnail...`);
          await new Promise((r) => setTimeout(r, 1500));
          const res = await fetch(thumbnailDataUrl);
          downloadFile(`${baseFileName}_Thumbnail.jpg`, await res.blob());
        }

        console.log(`âœ… [Packaging] All downloads completed!`);

        // Save content to backend database after successful download
        console.log(`ğŸ” [Packaging] Checking requirements for database save...`);
        console.log(`   currentCoreSubject: ${currentCoreSubject ? "âœ… EXISTS" : "âŒ MISSING"}`);
        console.log(`   currentVisualPrompt: ${currentVisualPrompt ? "âœ… EXISTS" : "âŒ MISSING"}`);
        console.log(`   metadata: ${metadata ? "âœ… EXISTS" : "âŒ MISSING"}`);

        if (currentCoreSubject && currentVisualPrompt && metadata) {
          console.log(`ğŸ’¾ [API] All requirements met! Saving content to database...`);

          const payload: ContentPayload = {
            jalaliDate: jalali,
            puzzleCard: {
              source: currentSource,
              category: preferences.topicCategory || "Unknown",
              narrativeLens: preferences.narrativeLens,
              musicMood: state.storyArc?.musicMood,
              musicTrack: currentMusicInfo?.title,
              musicSource: currentMusicInfo?.source,
              artStyle: preferences.style,
              pieceCount: preferences.pieceCount,
              duration: preferences.durationMinutes,
              shape: preferences.shape,
              material: preferences.material,
              movement: preferences.movement,
              soundEffects: {
                snap: "randomized",
                move: "randomized",
                wave: "randomized",
                destruct: "randomized",
              },
            },
            story: {
              coreSubject: currentCoreSubject,
              visualPrompt: currentVisualPrompt,
              hook: state.storyArc?.hook,
              buildup: state.storyArc?.buildup,
              climax: state.storyArc?.climax,
              reveal: state.storyArc?.reveal,
            },
            metadata: {
              title: metadata.title,
              description: metadata.description,
              tags: metadata.tags,
              hashtags: metadata.hashtags,
            },
            files: {
              videoFilename: `${baseFileName}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`,
              thumbnailFilename: thumbnailDataUrl ? `${baseFileName}_Thumbnail.jpg` : undefined,
              videoSizeMB: Number((videoBlob.size / 1024 / 1024).toFixed(2)),
            },
            analysis: {
              similarityScore: currentSimilarityScore,
              isUnique: currentSimilarityScore !== undefined ? currentSimilarityScore < 0.85 : true,
              generationAttempts: 1,
            },
          };

          const saveResult = await contentApi.saveContent(payload);

          if (saveResult.success) {
            console.log(`âœ… [API] Content saved to database successfully!`);
            console.log(`   Database ID: ${saveResult.data?._id}`);
            console.log(`ğŸ“¦ [PACKAGE] Saved: ${payload.files.videoFilename}, DB ID: ${saveResult.data?._id}`);
            updateProductionStep(
              "ğŸ“¦ PACKAGE",
              "completed",
              `Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ - DB ID: ${saveResult.data?._id?.substring(0, 8)}...`
            );
          } else {
            console.error(`âŒ [API] Failed to save content: ${saveResult.error}`);
            console.warn(`âš ï¸ [API] Content was downloaded but not saved to database`);
            updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ - Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³");
          }

          // Clear after recording
          setCurrentCoreSubject(null);
          setCurrentVisualPrompt(null);
          setCurrentMusicInfo(null);
          setCurrentSource("MANUAL");
          setCurrentSimilarityScore(undefined);
        } else {
          console.log(`â­ï¸ [API] Skipping database save (missing required data)`);
          updateProductionStep("ğŸ“¦ PACKAGE", "completed", "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ - Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³");
        }
      } finally {
        setLastVideoBlob(null);
        isExportingRef.current = false;

        // Log completion
        const currentIdx = state.currentQueueIdx;
        console.log(`âœ… [COMPLETE] Video ${currentIdx + 1} finished successfully`);

        setTimeout(() => {
          setState((prev) => {
            const nextIdx = prev.currentQueueIdx + 1;
            const hasNext = prev.isFullPackage && nextIdx < prev.queue.length;

            if (hasNext) {
              console.log(`\nâ¡ï¸  [AutoPilot] Moving to next video (${nextIdx + 1}/${prev.queue.length})\n`);
            } else {
              console.log(`\nğŸ [AutoPilot] All videos completed! Auto-Pilot finished.\n`);
            }

            return {
              ...prev,
              currentQueueIdx: hasNext ? nextIdx : -1,
              pipelineStep: "IDLE",
              isAutoMode: hasNext,
              isFullPackage: hasNext,
              isSolving: false,
              isRecording: false,
              progress: 0,
              imageUrl: hasNext ? prev.imageUrl : null,
            };
          });
        }, 2500);
      }
    },
    [
      metadata,
      thumbnailDataUrl,
      currentCoreSubject,
      currentVisualPrompt,
      currentMusicInfo,
      currentSource,
      currentSimilarityScore,
      state.storyArc,
      state.currentQueueIdx,
      preferences,
    ]
  );

  useEffect(() => {
    if (state.pipelineStep === "PACKAGING" && lastVideoBlob && !isExportingRef.current) {
      executePackaging(lastVideoBlob);
    }
  }, [state.pipelineStep, lastVideoBlob, executePackaging]);

  const processPipelineItem = useCallback(
    async (item: QueueItem, isManualOverride: boolean = false, queueIndex: number = 0) => {
      setState((s) => ({
        ...s,
        pipelineStep: "SCAN",
        isGenerating: true,
        error: null,
        imageUrl: isManualOverride ? s.imageUrl : null,
        progress: 0,
        storyArc: null,
      }));

      setLastVideoBlob(null);
      setMetadata(null);
      setThumbnailDataUrl(null);

      try {
        let sourceSubject = preferences.subject;
        let activeTopicType = TopicType.MANUAL;
        let categoryLabel = "Custom";

        if (!isManualOverride && state.isAutoMode) {
          // ğŸ¬ [AutoPilot] Starting video logging (use passed queueIndex to avoid stale closure)
          console.log(`ğŸ¬ [AutoPilot] Starting video ${queueIndex + 1}/${state.queue.length}`);

          // Initialize production steps for this video
          initializeProductionSteps();

          // Step 1: SCAN
          updateProductionStep("ğŸ“Š SCAN", "in_progress");
          console.log(`ğŸ“Š [SCAN] Content Type: ${item.source}`);
          updateProductionStep(
            "ğŸ“Š SCAN",
            "completed",
            `Ù†ÙˆØ¹: ${item.source}, Ù…Ø¯Øª: ${item.duration * 60}s, Ù‚Ø·Ø¹Ø§Øª: ${item.pieceCount}`
          );

          // Step 2: Sound FX
          updateProductionStep("ğŸ”Š SOUND FX", "in_progress");
          console.log(`ğŸ”Š [SOUND FX] Randomizing all sound effects...`);
          const { soundRandomizer } = await import("../services/soundRandomizer");
          const { useBackendMode } = await import("../contexts/BackendModeContext");
          // We can't use the hook here, so we check smartFetcher's mode instead
          const { smartFetcher } = await import("../services/smartFetcher");
          const preferBackend = smartFetcher.isBackendEnabled();
          await soundRandomizer.randomizeAllSounds(preferBackend);
          console.log(`ğŸ”Š [SOUND FX] Randomized: SNAP, MOVE, WAVE, DESTRUCT`);
          updateProductionStep("ğŸ”Š SOUND FX", "completed", "SNAP, MOVE, WAVE, DESTRUCT");

          if (item.source === "VIRAL") {
            let contentPackage;
            let coreSubject;
            let attempts = 0;
            const maxAttempts = 5;

            // Step 3: VALIDATION - Uniqueness check
            updateProductionStep("ğŸ” VALIDATION", "in_progress");

            // Validation loop: Keep generating until we find unique content
            while (attempts < maxAttempts) {
              attempts++;

              // Select a fresh category that hasn't been used recently
              const randomNiche = selectFreshCategory(VIRAL_CATEGORIES, 5);

              // Add unique variation to prevent repetitive prompts
              const variedTopic = addTopicVariation(randomNiche.topic);

              console.log(
                `\nğŸ¯ Attempt ${attempts}/${maxAttempts}: Generating content for "${randomNiche.label}"`
              );
              console.log(`ğŸ¨ Variation: ${variedTopic.substring(0, 100)}...`);

              // Generate content package
              contentPackage = await generateCoherentContentPackage(variedTopic, randomNiche.label);

              // Extract core subject for similarity checking
              coreSubject = await extractCoreSubject(
                contentPackage.visualPrompt,
                contentPackage.storyArc,
                randomNiche.label
              );

              // Check similarity via backend API
              console.log(`ğŸ” [API] Checking content similarity with backend...`);
              const similarityResult = await contentApi.checkSimilarity(coreSubject);

              if (similarityResult.success && similarityResult.data) {
                const isSimilar = similarityResult.data.isSimilar;
                const score =
                  similarityResult.data.similarityScore !== undefined
                    ? similarityResult.data.similarityScore
                    : 0;

                if (!isSimilar) {
                  console.log(`âœ… Content approved as unique! Proceeding with generation.`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (UNIQUE)`);
                  const scoreText = score.toFixed(2);
                  updateProductionStep(
                    "ğŸ” VALIDATION",
                    "completed",
                    `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯`
                  );
                  setCurrentSimilarityScore(score);
                  break; // Content is unique, exit loop
                } else {
                  console.log(`âŒ Content rejected as too similar (score: ${score})`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (DUPLICATE)`);
                  if (similarityResult.data.matchedContents?.length > 0) {
                    console.log(
                      `   Matched: ${similarityResult.data.matchedContents
                        .map((m: any) => m.title)
                        .join(", ")}`
                    );
                  }

                  if (attempts < maxAttempts) {
                    console.log(`   ğŸ”„ Regenerating with different parameters...\n`);
                    const scoreText = score.toFixed(2);
                    updateProductionStep(
                      "ğŸ” VALIDATION",
                      "in_progress",
                      `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - ØªÙ„Ø§Ø´ ${attempts}/${maxAttempts}`
                    );
                  }
                }
              } else {
                // If API check fails, log warning but continue (don't crash the pipeline)
                console.warn(`âš ï¸ [API] Similarity check failed: ${similarityResult.error}`);
                console.log(`   Proceeding with content generation (assuming unique)...`);
                updateProductionStep(
                  "ğŸ” VALIDATION",
                  "completed",
                  "Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ ÙØ±Ø¶ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ø¨ÙˆØ¯Ù†"
                );
                break;
              }
            }

            if (attempts >= maxAttempts) {
              console.warn(`âš ï¸ Max attempts reached. Using last generated content despite similarity.`);
              updateProductionStep("ğŸ” VALIDATION", "completed", `Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù…Ø­ØªÙˆØ§`);
            }

            // Store core subject and visual prompt for later recording
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);
            setCurrentSource("VIRAL");

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.VIRAL;
            categoryLabel = contentPackage.theme.category;

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep("ğŸ­ VARIETY", "in_progress");
            const { randomStyle, randomMovement, randomMaterial, randomShape } = randomizeVisualParameters();
            console.log(
              `ğŸ­ [VARIETY] Style: ${randomStyle}, Movement: ${randomMovement}, Material: ${randomMaterial}, Shape: ${randomShape}`
            );
            updateProductionStep(
              "ğŸ­ VARIETY",
              "completed",
              `Ø³Ø¨Ú©: ${randomStyle}, Ø­Ø±Ú©Øª: ${randomMovement}, Ù…Ø§Ø¯Ù‡: ${randomMaterial}, Ø´Ú©Ù„: ${randomShape}`
            );

            // Step 4: MUSIC - Smart Music Selection
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep("ğŸµ MUSIC", "in_progress");
            const musicResult = await selectSmartMusic({
              musicTracks,
              queueIndex: state.currentQueueIdx,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (musicResult) {
              console.log(`ğŸµ [MUSIC] Selected: ${musicResult.title} from ${musicResult.source}`);
              const titlePreview =
                musicResult.title.length > 40
                  ? musicResult.title.substring(0, 40) + "..."
                  : musicResult.title;
              updateProductionStep(
                "ğŸµ MUSIC",
                "completed",
                `Ù…Ù†Ø¨Ø¹: ${musicResult.source}, Ù‚Ø·Ø¹Ù‡: ${titlePreview}`
              );
              setCurrentMusicInfo(musicResult);
              await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, musicResult.blob);
            } else {
              updateProductionStep("ğŸµ MUSIC", "completed", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ");
              setCurrentMusicInfo(null);
              musicBufferRef.current = null;
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep("ğŸ¨ GENERATE", "in_progress");
            const art = await generateArtImage(randomStyle, contentPackage.visualPrompt);
            console.log(
              `ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${
                contentPackage.storyArc.hook
              }`
            );
            const hookPreview =
              contentPackage.storyArc.hook.length > 50
                ? contentPackage.storyArc.hook.substring(0, 50) + "..."
                : contentPackage.storyArc.hook;
            updateProductionStep("ğŸ¨ GENERATE", "completed", `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø¯Ø§Ø³ØªØ§Ù†: ${hookPreview}`);

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: randomStyle,
              movement: randomMovement,
              material: randomMaterial,
              shape: randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep("ğŸ“‹ METADATA", "in_progress");
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || "Ù†Ø§Ù…Ø´Ø®Øµ";
            const titlePreview =
              metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + "..." : metadataTitle;
            updateProductionStep("ğŸ“‹ METADATA", "completed", `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "in_progress");
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„");

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep("ğŸ¬ ANIMATE", "in_progress", "Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...");
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(() => {
                setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                updateProductionStep("ğŸ¬ ANIMATE", "completed", "Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯");
                updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...");
              }, 10000);
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          } else if (item.source === "NARRATIVE") {
            // Use new Coherent Content Package for NARRATIVE mode too
            const randomNiche = VIRAL_CATEGORIES[Math.floor(Math.random() * VIRAL_CATEGORIES.length)];

            console.log(`ğŸ¯ NARRATIVE Mode: Generating coherent package for "${randomNiche.label}"`);
            const contentPackage = await generateCoherentContentPackage(randomNiche.topic, randomNiche.label);

            // Extract core subject for database save
            const coreSubject = await extractCoreSubject(
              contentPackage.visualPrompt,
              contentPackage.storyArc,
              randomNiche.label
            );

            // Store for later database save
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);
            setCurrentSource("NARRATIVE");

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.NARRATIVE;
            categoryLabel = contentPackage.theme.category;

            // NARRATIVE skips VALIDATION step (no similarity check needed for historical content)
            updateProductionStep("ğŸ” VALIDATION", "completed", "Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ - Ù…Ø­ØªÙˆØ§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ");
            setCurrentSimilarityScore(undefined);

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep("ğŸ­ VARIETY", "in_progress");
            const narrativeVisual = randomizeVisualParameters();
            console.log(
              `ğŸ­ [VARIETY] Style: ${narrativeVisual.randomStyle}, Movement: ${narrativeVisual.randomMovement}`
            );
            updateProductionStep(
              "ğŸ­ VARIETY",
              "completed",
              `Ø³Ø¨Ú©: ${narrativeVisual.randomStyle}, Ø­Ø±Ú©Øª: ${narrativeVisual.randomMovement}, Ù…Ø§Ø¯Ù‡: ${narrativeVisual.randomMaterial}, Ø´Ú©Ù„: ${narrativeVisual.randomShape}`
            );

            // Step 4: MUSIC - Smart Music Selection (use passed queueIndex for correct track per video)
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep("ğŸµ MUSIC", "in_progress");
            const narrativeMusicResult = await selectSmartMusic({
              musicTracks,
              queueIndex,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (narrativeMusicResult) {
              console.log(
                `ğŸµ [MUSIC] Selected: ${narrativeMusicResult.title} from ${narrativeMusicResult.source}`
              );
              const musicTitlePreview =
                narrativeMusicResult.title.length > 40
                  ? narrativeMusicResult.title.substring(0, 40) + "..."
                  : narrativeMusicResult.title;
              updateProductionStep(
                "ğŸµ MUSIC",
                "completed",
                `Ù…Ù†Ø¨Ø¹: ${narrativeMusicResult.source}, Ù‚Ø·Ø¹Ù‡: ${musicTitlePreview}`
              );
              setCurrentMusicInfo(narrativeMusicResult);
              await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, narrativeMusicResult.blob);
            } else {
              updateProductionStep("ğŸµ MUSIC", "completed", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ");
              setCurrentMusicInfo(null);
              musicBufferRef.current = null;
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep("ğŸ¨ GENERATE", "in_progress");
            const art = await generateArtImage(narrativeVisual.randomStyle, contentPackage.visualPrompt);
            console.log(
              `ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${
                contentPackage.storyArc.hook
              }`
            );
            const narrativeHookPreview =
              contentPackage.storyArc.hook.length > 50
                ? contentPackage.storyArc.hook.substring(0, 50) + "..."
                : contentPackage.storyArc.hook;
            updateProductionStep(
              "ğŸ¨ GENERATE",
              "completed",
              `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø¯Ø§Ø³ØªØ§Ù†: ${narrativeHookPreview}`
            );

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: narrativeVisual.randomStyle,
              movement: narrativeVisual.randomMovement,
              material: narrativeVisual.randomMaterial,
              shape: narrativeVisual.randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep("ğŸ“‹ METADATA", "in_progress");
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || "Ù†Ø§Ù…Ø´Ø®Øµ";
            const titlePreview =
              metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + "..." : metadataTitle;
            updateProductionStep("ğŸ“‹ METADATA", "completed", `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "in_progress");
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„");

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep("ğŸ¬ ANIMATE", "in_progress", "Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...");
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(() => {
                setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                updateProductionStep("ğŸ¬ ANIMATE", "completed", "Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯");
                updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...");
              }, 10000);
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          } else if (item.source === "BREAKING") {
            // Breaking News Mode: AI Search for trending topics
            console.log(`ğŸ¯ BREAKING Mode: Fetching trending topics via AI Search...`);

            let contentPackage;
            let coreSubject;
            let attempts = 0;
            const maxAttempts = 5;

            // Step 3: VALIDATION - Uniqueness check with trending topics
            updateProductionStep("ğŸ” VALIDATION", "in_progress");

            // Validation loop with trending topics
            while (attempts < maxAttempts) {
              attempts++;

              // Fetch trending topics
              const trendingTopics = await getTrendingTopics();
              const randomTopic = trendingTopics[Math.floor(Math.random() * trendingTopics.length)];

              console.log(`\nğŸ¯ Attempt ${attempts}/${maxAttempts}: Generating breaking news content`);
              console.log(`ğŸ“° Topic: ${randomTopic}`);

              // Generate content package
              contentPackage = await generateCoherentContentPackage(randomTopic, "Breaking News");

              // Extract core subject for similarity checking
              coreSubject = await extractCoreSubject(
                contentPackage.visualPrompt,
                contentPackage.storyArc,
                "Breaking News"
              );

              // Check similarity via backend API
              console.log(`ğŸ” [API] Checking content similarity with backend...`);
              const similarityResult = await contentApi.checkSimilarity(coreSubject);

              if (similarityResult.success && similarityResult.data) {
                const isSimilar = similarityResult.data.isSimilar;
                const score =
                  similarityResult.data.similarityScore !== undefined
                    ? similarityResult.data.similarityScore
                    : 0;

                if (!isSimilar) {
                  console.log(`âœ… Content approved as unique! Proceeding with generation.`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (UNIQUE)`);
                  const scoreText = score.toFixed(2);
                  updateProductionStep(
                    "ğŸ” VALIDATION",
                    "completed",
                    `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - Ø®Ø¨Ø± Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯`
                  );
                  setCurrentSimilarityScore(score);
                  break;
                } else {
                  console.log(`âŒ Content rejected as too similar (score: ${score})`);
                  if (attempts < maxAttempts) {
                    console.log(`   ğŸ”„ Regenerating with different topic...\n`);
                    const scoreText = score.toFixed(2);
                    updateProductionStep(
                      "ğŸ” VALIDATION",
                      "in_progress",
                      `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - ØªÙ„Ø§Ø´ ${attempts}/${maxAttempts}`
                    );
                  }
                }
              } else {
                console.warn(`âš ï¸ [API] Similarity check failed: ${similarityResult.error}`);
                console.log(`   Proceeding with content generation (assuming unique)...`);
                updateProductionStep(
                  "ğŸ” VALIDATION",
                  "completed",
                  "Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ ÙØ±Ø¶ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ø¨ÙˆØ¯Ù†"
                );
                break;
              }
            }

            if (attempts >= maxAttempts) {
              console.warn(`âš ï¸ Max attempts reached. Using last generated content despite similarity.`);
              updateProductionStep("ğŸ” VALIDATION", "completed", `Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø®Ø¨Ø±`);
            }

            // Store core subject and visual prompt
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);
            setCurrentSource("BREAKING");

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.BREAKING;
            categoryLabel = "Breaking News";

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep("ğŸ­ VARIETY", "in_progress");
            const breakingVisual = randomizeVisualParameters();
            console.log(
              `ğŸ­ [VARIETY] Style: ${breakingVisual.randomStyle}, Movement: ${breakingVisual.randomMovement}`
            );
            updateProductionStep(
              "ğŸ­ VARIETY",
              "completed",
              `Ø³Ø¨Ú©: ${breakingVisual.randomStyle}, Ø­Ø±Ú©Øª: ${breakingVisual.randomMovement}, Ù…Ø§Ø¯Ù‡: ${breakingVisual.randomMaterial}, Ø´Ú©Ù„: ${breakingVisual.randomShape}`
            );

            // Step 4: MUSIC - Smart Music Selection (use passed queueIndex for correct track per video)
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep("ğŸµ MUSIC", "in_progress");
            const breakingMusicResult = await selectSmartMusic({
              musicTracks,
              queueIndex,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (breakingMusicResult) {
              console.log(
                `ğŸµ [MUSIC] Selected: ${breakingMusicResult.title} from ${breakingMusicResult.source}`
              );
              const breakingMusicTitlePreview =
                breakingMusicResult.title.length > 40
                  ? breakingMusicResult.title.substring(0, 40) + "..."
                  : breakingMusicResult.title;
              updateProductionStep(
                "ğŸµ MUSIC",
                "completed",
                `Ù…Ù†Ø¨Ø¹: ${breakingMusicResult.source}, Ù‚Ø·Ø¹Ù‡: ${breakingMusicTitlePreview}`
              );
              setCurrentMusicInfo(breakingMusicResult);
              await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, breakingMusicResult.blob);
            } else {
              updateProductionStep("ğŸµ MUSIC", "completed", "Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ");
              setCurrentMusicInfo(null);
              musicBufferRef.current = null;
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep("ğŸ¨ GENERATE", "in_progress");
            const art = await generateArtImage(breakingVisual.randomStyle, contentPackage.visualPrompt);
            console.log(
              `ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${
                contentPackage.storyArc.hook
              }`
            );
            const breakingHookPreview =
              contentPackage.storyArc.hook.length > 50
                ? contentPackage.storyArc.hook.substring(0, 50) + "..."
                : contentPackage.storyArc.hook;
            updateProductionStep("ğŸ¨ GENERATE", "completed", `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø®Ø¨Ø±: ${breakingHookPreview}`);

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: breakingVisual.randomStyle,
              movement: breakingVisual.randomMovement,
              material: breakingVisual.randomMaterial,
              shape: breakingVisual.randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep("ğŸ“‹ METADATA", "in_progress");
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || "Ù†Ø§Ù…Ø´Ø®Øµ";
            const titlePreview =
              metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + "..." : metadataTitle;
            updateProductionStep("ğŸ“‹ METADATA", "completed", `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "in_progress");
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep("ğŸ–¼ï¸ THUMBNAIL", "completed", "Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„");

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep("ğŸ¬ ANIMATE", "in_progress", "Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...");
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(() => {
                setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                updateProductionStep("ğŸ¬ ANIMATE", "completed", "Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯");
                updateProductionStep("ğŸ¥ RECORD", "in_progress", "Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...");
              }, 10000);
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          }
        } else {
          // MANUAL mode - use Coherent Content Package for consistency
          const randomNiche = VIRAL_CATEGORIES[Math.floor(Math.random() * VIRAL_CATEGORIES.length)];

          console.log(`ğŸ¯ MANUAL Mode: Generating coherent package for "${randomNiche.label}"`);
          const contentPackage = await generateCoherentContentPackage(sourceSubject, randomNiche.label);

          // Extract core subject for database save
          const coreSubject = await extractCoreSubject(
            contentPackage.visualPrompt,
            contentPackage.storyArc,
            randomNiche.label
          );

          // Store for later database save
          setCurrentCoreSubject(coreSubject);
          setCurrentVisualPrompt(contentPackage.visualPrompt);
          setCurrentSource("MANUAL");
          setCurrentSimilarityScore(undefined);

          setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
          // ğŸµ Smart Music Selection with Priority (Manual Mode doesn't use queue)
          const manualMusicResult = await selectSmartMusic({
            musicTracks,
            queueIndex: 0, // Manual mode doesn't track queue index
            musicMood: contentPackage.theme.musicMood,
            topic: sourceSubject,
            fetchAudioBlob,
            onAddCloudTrack,
            setActiveTrackName,
            audioRef,
          });
          setCurrentMusicInfo(manualMusicResult);
          await decodeAndStoreMusicBuffer(audioRef, musicBufferRef, manualMusicResult.blob);

          setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
          const finalStyle = preferences.style;
          const art = await generateArtImage(finalStyle, contentPackage.visualPrompt);

          setPreferences((p) => ({
            ...p,
            subject: contentPackage.visualPrompt,
            narrativeLens: contentPackage.theme.narrativeLens,
          }));

          setState((s) => ({
            ...s,
            imageUrl: art.imageUrl,
            storyArc: contentPackage.storyArc,
            docSnippets: [],
            isGenerating: false,
            pipelineStep: "METADATA",
          }));

          setIsMetadataLoading(true);
          setMetadata(contentPackage.metadata);
          setIsMetadataLoading(false);

          setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
          setState((s) => ({ ...s, pipelineStep: "IDLE" }));
        }
      } catch (e) {
        console.error("Pipeline error:", e);
        setState((s) => ({
          ...s,
          isAutoMode: false,
          isGenerating: false,
          pipelineStep: "IDLE",
          error: "Neural Engine Sync Error",
        }));
      }
    },
    [preferences, state.isAutoMode, onAddCloudTrack, setActiveTrackName, setPreferences, fetchAudioBlob]
  );

  const toggleAutoMode = useCallback(() => {
    setState((s) => {
      const active = !s.isAutoMode;
      return {
        ...s,
        isAutoMode: active,
        isFullPackage: active,
        pipelineStep: active ? "IDLE" : s.pipelineStep,
        queue: active
          ? [
              // Queue mØ·Ø§Ø¨Ù‚ AUTO_PILOT_STRATEGY.md v6.0
              { duration: 0.5, source: "VIRAL", pieceCount: 100 }, // 30s - Hook & Fast Reveal
              { duration: 0.75, source: "VIRAL", pieceCount: 300 }, // 45s - Retention Test
              { duration: 1.0, source: "VIRAL", pieceCount: 500 }, // 60s - Full Engagement
              { duration: 1.5, source: "VIRAL", pieceCount: 2000 }, // 90s - Deep Dive
              { duration: 1.0, source: "BREAKING", pieceCount: 500 }, // 60s - Trending & Timely
              { duration: 1.0, source: "NARRATIVE", pieceCount: 900 }, // 60s - High Detail Finale
            ]
          : s.queue,
        currentQueueIdx: active ? 0 : s.currentQueueIdx,
      };
    });
  }, []);

  useEffect(() => {
    if (state.isAutoMode && state.pipelineStep === "IDLE" && state.currentQueueIdx !== -1) {
      processPipelineItem(state.queue[state.currentQueueIdx], false, state.currentQueueIdx);
    }
  }, [state.isAutoMode, state.pipelineStep, state.currentQueueIdx, processPipelineItem]);

  return {
    state,
    setState,
    metadata,
    isMetadataLoading,
    thumbnailDataUrl,
    setThumbnailDataUrl,
    setLastVideoBlob,
    processPipelineItem,
    toggleAutoMode,
  };
};
